{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": "import os, sys\nsys.path.append('/root/catkin_ws/src/primitives/')\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.mplot3d import axes3d\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport trimesh\nimport networkx\n\nfrom open3d import JVisualizer\n\nimport copy\nimport time\nimport argparse\nimport numpy as np\nfrom multiprocessing import Process, Pipe, Queue\nimport pickle\nimport rospy\nimport copy\nimport signal\nimport open3d\nfrom IPython import embed\n\nfrom yacs.config import CfgNode as CN\nfrom closed_loop_experiments import get_cfg_defaults"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['planner_args', 'goal', 'contact_obj_frame', 'contact_world_frame', 'transformation', 'start', 'result', 'keypoints_start', 'contact_pcd', 'keypoints_goal', 'obs', 'goal_face']\n"
    }
   ],
   "source": "with open ('/root/catkin_ws/src/primitives/data/grasp/face_ind_test_0/2.pkl', 'rb') as f:\n    grasp_data = pickle.load(f)\n    \nprint(grasp_data.keys())"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['planner_args', 'goal', 'contact_obj_frame', 'contact_world_frame', 'transformation', 'start', 'result', 'keypoints_start', 'contact_pcd', 'keypoints_goal', 'obs']\n"
    }
   ],
   "source": "with open ('/root/catkin_ws/src/primitives/data/pull/face_ind_large_0/1.pkl', 'rb') as f:\n    pull_data = pickle.load(f)\n    \nprint(pull_data.keys())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Training data: \n## Inputs: \nInitial observation, different representations:\n- ```'start'```: pose ```[x_pos, y_pos, z_pos, x_ori, y_ori, z_ori, w_ori]```\n- ```'keypoints_start'```: 3D location of box corners at start pose\n- ```'obs':'pcd_pts'```: Point cloud of box from 3 different viewpoints, with same global coordinate sys. Can be fused with np.concatenate (see below)\n\nGoal, different representations:\n- ```'goal'```: pose\n- ```'keypoints_goal'```: 3D location of box corners at goal pose"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": "# start observation\nstart = pull_data['start']\nkeypoints_start = pull_data['keypoints_start']\npcd_pts = pull_data['obs']['pcd_pts']\npcd_pts_start = np.concatenate(pcd_pts, axis=0)\n\n# goal\ngoal = pull_data['goal']\nkeypoints_goal = pull_data['keypoints_goal']"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Outputs:\n## Pulling/Pushing (single arm)\nRobot palm pose in the object frame, for active arm -- active arm currently based on which side of the table the object starts on. TODO perhaps includes predicting which arm is active, once we move to more diverse data. For now, everything for pulling happens with the right arm\n- ```'contact_obj_frame'```: pose ```[x_pos, y_pos, z_pos, x_ori, y_ori, z_ori, w_ori]```, specified with respect to the coordinate system located at the object center of mass at the start pose\n\n## Grasping/Pivoting (dual arm)\n\nRight and left robot palm pose in the object frame\n- ```'contact_obj_frame':'right'```: right palm pose ```[x_pos, y_pos, z_pos, x_ori, y_ori, z_ori, w_ori]```, specified with respect to the coordinate system located at the object center of mass at the start pose\n- ```'contact_obj_frame':'left'```: left palm pose ```[x_pos, y_pos, z_pos, x_ori, y_ori, z_ori, w_ori]```, specified with respect to the coordinate system located at the object center of mass at the start pose"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": "# right palm contact for pulling\ncontact_r = pull_data['contact_obj_frame']\n\n# both palms contact for grasping\ncontact_r = grasp_data['contact_obj_frame']['right']\ncontact_l = grasp_data['contact_obj_frame']['left']"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## helpers\n\n# load minibatch\n# def load_minibatch(M, datatype='pose')\n\n\n## setup\n\n# load model architecture (encoder and decoder)\n\n# setup optimizer\n\n# setup loss function\n\n## train loop\n\n# for epoch in num_epochs:\n# for minibatch in minibatch_size / data_size:\n# forward pass, compute loss, backprop, optimizer.step\n# look at loss"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Testing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## setup\n\n# distribution to sample from for start/goal (same as in training)\n\n# load trained model\n\n## eval\n\n# sample from the latent space and use the decoder/generator to produce contacts, visualize below"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Metadata keys: \n"
    }
   ],
   "source": "# with open('/root/catkin_ws/src/primitives/data/pull/face_ind_large_0/metadata.pkl', 'rb') as mf:\n#     metadata = pickle.load(mf)\nwith open('/root/catkin_ws/src/primitives/data/grasp/face_ind_test_0/metadata.pkl', 'rb') as mf:\n    metadata = pickle.load(mf)\n\n\nprint('Metadata keys: ')\ndynamics_info = metadata['dynamics']\nmesh_file = metadata['mesh_file']\npalm_mesh_file = '/root/catkin_ws/src/config/descriptions/meshes/mpalm/mpalms_all_coarse.stl'\ntable_mesh_file = '/root/catkin_ws/src/config/descriptions/meshes/table/table_top.stl'\ncfg = metadata['cfg']"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Visualize contact on object"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": "def vis_palms(data, name='pull'):\n    obj_mesh = trimesh.load_mesh(mesh_file)\n    r_palm_mesh = trimesh.load_mesh(palm_mesh_file)\n    l_palm_mesh = trimesh.load_mesh(palm_mesh_file)\n    table_mesh = trimesh.load_mesh(table_mesh_file)\n    \n    obj_pos_world = data['start'][:3]\n    obj_ori_world = data['start'][3:]\n    obj_ori_mat = common.quat2rot(obj_ori_world)\n    h_trans = np.zeros((4, 4))\n    h_trans[:3, :3] = obj_ori_mat\n    h_trans[:-1, -1] = obj_pos_world\n    h_trans[-1, -1] = 1\n\n    obj_mesh.apply_transform(h_trans)\n    if name == 'pull':\n        tip_contact_r_obj = util.list2pose_stamped(data['contact_obj_frame'])\n        tip_contact_r = util.convert_reference_frame(\n            pose_source=tip_contact_r_obj,\n            pose_frame_target=util.unit_pose(),\n            pose_frame_source=util.list2pose_stamped(data['start']))\n\n        wrist_contact_r = util.convert_reference_frame(\n            pose_source=util.list2pose_stamped(cfg.TIP_TO_WRIST_TF),\n            pose_frame_target=util.unit_pose(),\n            pose_frame_source=tip_contact_r)\n\n        wrist_contact_r_list = util.pose_stamped2list(wrist_contact_r)\n        \n        palm_pos_world_r = wrist_contact_r_list[:3]\n        palm_ori_world_r = wrist_contact_r_list[3:]\n        palm_ori_mat = common.quat2rot(palm_ori_world_r)\n        h_trans = np.zeros((4, 4))\n        h_trans[:3, :3] = palm_ori_mat\n        h_trans[:-1, -1] = palm_pos_world_r\n        h_trans[-1, -1] = 1\n\n        r_palm_mesh.apply_transform(h_trans)      \n        \n        scene = trimesh.Scene([obj_mesh, r_palm_mesh, table_mesh])        \n    else:\n        tip_contact_r_obj = util.list2pose_stamped(data['contact_obj_frame']['right'])\n        tip_contact_l_obj = util.list2pose_stamped(data['contact_obj_frame']['left'])\n\n        tip_contact_r = util.convert_reference_frame(\n            pose_source=tip_contact_r_obj,\n            pose_frame_target=util.unit_pose(),\n            pose_frame_source=util.list2pose_stamped(data['start']))\n            \n        tip_contact_l = util.convert_reference_frame(\n            pose_source=tip_contact_l_obj,\n            pose_frame_target=util.unit_pose(),\n            pose_frame_source=util.list2pose_stamped(data['start']))            \n            \n        wrist_contact_r = util.convert_reference_frame(\n            pose_source=util.list2pose_stamped(cfg.TIP_TO_WRIST_TF),\n            pose_frame_target=util.unit_pose(),\n            pose_frame_source=tip_contact_r)\n\n        wrist_contact_l = util.convert_reference_frame(\n            pose_source=util.list2pose_stamped(cfg.TIP_TO_WRIST_TF),\n            pose_frame_target=util.unit_pose(),\n            pose_frame_source=tip_contact_l)\n\n        wrist_contact_r_list = util.pose_stamped2list(wrist_contact_r)\n        wrist_contact_l_list = util.pose_stamped2list(wrist_contact_l)\n        \n        palm_pos_world_r = wrist_contact_r_list[:3]\n        palm_ori_world_r = wrist_contact_r_list[3:]\n        palm_ori_mat = common.quat2rot(palm_ori_world_r)\n        h_trans = np.zeros((4, 4))\n        h_trans[:3, :3] = palm_ori_mat\n        h_trans[:-1, -1] = palm_pos_world_r\n        h_trans[-1, -1] = 1\n\n        r_palm_mesh.apply_transform(h_trans)\n        \n        palm_pos_world_l = wrist_contact_l_list[:3]\n        palm_ori_world_l = wrist_contact_l_list[3:]\n        palm_ori_mat = common.quat2rot(palm_ori_world_l)\n        h_trans = np.zeros((4, 4))\n        h_trans[:3, :3] = palm_ori_mat\n        h_trans[:-1, -1] = palm_pos_world_l\n        h_trans[-1, -1] = 1\n\n        l_palm_mesh.apply_transform(h_trans)        \n        \n        scene = trimesh.Scene([obj_mesh, r_palm_mesh, l_palm_mesh, table_mesh])\n    return scene"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "SceneViewer(width=1800, height=1350)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "# scene = vis_palms(pull_data, name='pull')\nscene = vis_palms(grasp_data, name='grasp')\n\nscene.show(viewer='gl')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
